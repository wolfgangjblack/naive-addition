{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit and HuggingFace Starter Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( ü§ó the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the session, you will "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- know how to work with APIs\n",
    "- feel more comfortable navigating thru documentation, even inspecting the source code\n",
    "- understand what a `pipeline` object is in HuggingFace\n",
    "- perform sentiment analysis using `pipeline`\n",
    "- run a python script in command line and get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- At the end of each task, commit* the work into your own remote repo\n",
    "- After completing all three tasks, make sure to push the notebook containing all code blocks and output cells to your remote repo\n",
    "- Submit the link to the notebook in Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\***NEVER** commit a notebook displaying errors unless it is instructed otherwise. However, commit often; recall git ABC = **A**lways **B**e **C**ommitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task I: Instantiate a Reddit API Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first task is to instantiate a Reddit API object using [PRAW](https://praw.readthedocs.io/en/stable/), through which you will retrieve data. PRAW is a wrapper for [Reddit API](https://www.reddit.com/dev/api) that makes interacting with the Reddit API easier unless you are already an expert of [`requests`](https://docs.python-requests.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 0.  Get updates from `FourthBrain/MLE-7`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Under your forked local repo, **fetch** and download new updates from repo `FourthBrain/MLE-7` locally so you can start development. \n",
    "    \n",
    "<details>\n",
    "<summary>If you haven't added `FourthBrain/MLE-7` as a remote repo, click here for instructions:</summary>   \n",
    "You fork repo `FourthBrain/MLE-7` to `yourhandle/MLE-7`, clone it locally, and now you are under directory `MLE-7`. By default, you will see one server name `origin` pointing to your repo:  \n",
    "    \n",
    "```\n",
    "$git remote -v \n",
    "origin  git@github.com:yourhandle/MLE-7.git (fetch)\n",
    "origin  git@github.com:yourhandle/MLE-7.git (push)\n",
    "```\n",
    "\n",
    "Think of fetch = read and push = write. \n",
    "\n",
    "Now add `FourthBrain/MLE-7` as a remote repo\n",
    "\n",
    "```\n",
    "$git add remote fourthbrain git@github.com:FourthBrain/MLE-7.git\n",
    "$git remote -v\n",
    "fourthbrain\tgit@github.com:FourthBrain/MLE-7.git (fetch)\n",
    "fourthbrain\tgit@github.com:FourthBrain/MLE-7.git (push)\n",
    "origin git@github.com:yourhandle/MLE-7.git (fetch)\n",
    "origin git@github.com:yourhandle/MLE-7.git (push)\n",
    "```\n",
    "\n",
    "then before each session starts, run `git fetch fourthbrain` to get updates (why not `git pull`?).\n",
    "\n",
    "check out [Working with Remotes](https://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes) for more explanations.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "conda activate {your_virtual_environment_name}\n",
    "pip install -U transformers praw torch numpy pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U transformers praw torch numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2. Create a new app on Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new app on Reddit and save secret tokens; refer to [post in medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Create a Reddit account if you don't have one, log into your account.\n",
    "- To access the API, we need create an app. Slight updates, on the website, you need to navigate to `preference` > `app`, or click [this link](https://www.reddit.com/prefs/apps) and scroll all the way down. \n",
    "- Click to create a new app, fill in the **name**, choose `script`, fill in  **description** and **redirect url** ( The redirect URI is where the user is sent after they've granted OAuth access to your application; more info [here](and details are in [](https://github.com/reddit-archive/reddit/wiki/OAuth2) for our purpose, you can enter some random url, e.g., www.google.com; ) as shown below.\n",
    "    <img src=\"https://miro.medium.com/max/700/1*lRBvxpIe8J2nZYJ6ucMgHA.png\" width=\"500\"/>\n",
    "- Jolt down `client_id` (left upper corner) and `client_secret` \n",
    "\n",
    "    NOTE: CLIENT_ID refers to 'personal use script\" and CLIENT_SECRET to secret.\n",
    "    <div>\n",
    "    <img src=\"https://miro.medium.com/max/700/1*7cGAKth1PMrEf2sHcQWPoA.png\" width=\"300\"/>\n",
    "    </div>\n",
    "\n",
    "- Create `secrets.py` in the same directory with this notebook, fill in `client_id` and `secret_id` obtained from the last step. We will need to import those constants in the next step.\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = {client_id}\n",
    "    REDDIT_API_CLIENT_SECRET = {secret_id}\n",
    "    REDDIT_API_USER_AGENT = {can_be_any_string, e.g., : \"BotBot\"}\n",
    "    ```\n",
    "- Add `secrets.py` to your `.gitignore` file if not already done. NEVER push credentials to a repo, private or public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Instantiate a `Reddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you are ready to create a read-only `Reddit` instance. Refer to [documentation](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import secrets\n",
    "\n",
    "# Create a Reddit object which allows us to interact with the Reddit API\n",
    "reddit = praw.Reddit(\n",
    "     client_id=secrets.REDDIT_API_CLIENT_ID,\n",
    "    client_secret=secrets.REDDIT_API_CLIENT_SECRET,\n",
    "    user_agent=secrets.REDDIT_API_USER_AGENT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(reddit.read_only) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "```<praw.reddit.Reddit object at 0x10f8a0ac0>```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Instantiate a `subreddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly, create a `subreddit` object for your favorite subreddit and inspect the object. The expected output you will see ar from `r/machinelearning` unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('finalfantasy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the display name of the subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finalfantasy'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    machinelearning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How about its title, is it different from the display name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Fantasy\n"
     ]
    }
   ],
   "source": [
    "print(subreddit.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    Machine Learning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print out the description of the subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Welcome!\n",
      "\n",
      ">* Subreddit Archives\n",
      "* [Detailed Subreddit Rules](https://www.reddit.com/r/FinalFantasy/wiki/rules)\n",
      "* [Related Subreddits](https://www.reddit.com/r/FinalFantasy/wiki/relatedsubreddits)\n",
      "* [Subreddit Survey Results](https://docs.google.com/forms/d/e/1FAIpQLSeSTiv5i0A9j5KSK7h1AZVC9EUdB0a2IGucDxIEs1JzKYRH8w/viewanalytics)\n",
      "* [Subreddit Banner Archive](https://www.reddit.com/r/FinalFantasy/wiki/bannercontests)\n",
      "* [Promptography Event Album](https://www.reddit.com/r/FinalFantasy/wiki/promptography)\n",
      "* [Giveaways/Charity Events](https://www.reddit.com/r/FinalFantasy/wiki/giveaways)\n",
      "* [Megathreads](https://www.reddit.com/r/FinalFantasy/wiki/megathreads)\n",
      "* [Discussion Threads](https://www.reddit.com/r/FinalFantasy/wiki/weeklydiscussions)\n",
      "\n",
      ">#\n",
      "\n",
      ">* Upcoming Releases\n",
      "* [FFVII Remake Part 2](https://www.reddit.com/r/FinalFantasy/wiki/finalfantasyviiremake)\n",
      "* [Final Fantasy XVI](https://www.reddit.com/r/FinalFantasy/wiki/finalfanttasyxvi)\n",
      "\n",
      ">#\n",
      "\n",
      ">* New to Final Fantasy?\n",
      "* [Series FAQ](https://www.reddit.com/r/FinalFantasy/wiki/fffaq)\n",
      "* [Where do I start?](https://www.reddit.com/r/FinalFantasy/wiki/wheretostart)\n",
      "* [Which version should I play?](https://www.reddit.com/r/FinalFantasy/wiki/whichversion)\n",
      "* [Game Rankings and Reviews](https://www.reddit.com/r/FinalFantasy/wiki/ffrankings)\n",
      "* [Full List of Games with Descriptions](https://www.reddit.com/r/FinalFantasy/wiki/index/gamelist)\n",
      "\n",
      "[](https://finalfantasy.fandom.com/wiki/Final_Fantasy_IV)\n",
      "\n",
      "#####[FF7R voice actor AMA](https://www.reddit.com/r/FinalFantasy/comments/g1xq7g/ama_ask_me_anything_with_various_final_fantasy/)\n",
      "\n",
      "[Filter FFXVI Content](https://pp.reddit.com/r/FinalFantasy/#pp)\n",
      "\n",
      "[](https://discordapp.com/invite/Jaw79wj)\n",
      "\n",
      "[](https://twitter.com/RedditFFantasy)\n",
      "\n",
      "[](https://www.youtube.com/playlist?list=PLjnQ0Nvdre15R6dvNJx5Z9Ub14nTWGUPY)\n",
      "\n",
      "[](https://steamcommunity.com/groups/redditfinalfantasy)\n",
      "\n",
      "[](https://docs.google.com/forms/d/e/1FAIpQLSeFIbUNRGVKY6mra3y6ZMioDr5RJoEhs3M3eJBZsOqKYCL1Fw/viewform?usp=sf_link)\n",
      "\n",
      "[Take our 2021 Subreddit Survey!](https://docs.google.com/forms/d/e/1FAIpQLScsKCcHVmTNwlGIBwtpdM1_LNanytpjl2-cMcv_fzE7umhgZg/viewform?usp=sf_link)\n",
      "\n",
      "[](https://eu.finalfantasyxiv.com/lodestone/freecompany/9231394073691071527/)\n",
      "\n",
      "[Remove VII Remake Filter](https://www.reddit.com/r/FinalFantasy/)\n",
      "\n",
      "\n",
      "*A subreddit for all things Final Fantasy!*\n",
      "\n",
      "**Please tag major spoilers.** Remember that there may be people reading that are new to the franchise!\n",
      "\n",
      "```>!Spoiler goes here!<```= >!Spoiler goes here!<\n",
      "\n",
      "##Community Calendar\n",
      "\n",
      "Date|Community Event|\n",
      ":---:|:------:\n",
      "12/1| FFT Let's Play Discussion Week 1 **(20% Checkpoint)**\n",
      "12/8| FFT Let's Play Discussion Week 2 **(40% Checkpoint)**\n",
      "12/15| FFT Let's Play Discussion Week 3 **(60% Checkpoint)**\n",
      "12/22| FFT Let's Play Discussion Week 4 **(80% Checkpoint)**\n",
      "12/29| FFT Let's Play Discussion Week 5 **(100% Checkpoint)**\n",
      "4/10/2020|**FFVII Remake (Part 1) Release Date**\n",
      "\n",
      "\n",
      "##Subreddit Rules\n",
      "1. **Keep it Civil** - Please be polite and respectful to others. Don't call people names or make personal attacks. We'll remove harassing comments, and ban repeat offenders. \n",
      "\n",
      "2. **Be Careful with spoilers** - Spoilers don't expire, no matter the game's age. Don't include major spoilers in a post title. Please put \"[SPOILER]\" in the title if the link or comments will contain untagged spoilers. Use spoiler markup in your comments if you chose not to put \"[SPOILER]\" in the title. Maliciously spoiling games for others will result in a temporary ban.\n",
      "\n",
      "3. **Self Promotion** - Self promotion can include any content in a post or comment that directs users to your own personal platform outside of Reddit (YouTube channel, social media, blog etc). We allow these posts at a ratio of 10:1 comments to self-promo posts. Links inside of reddit (Reddit image video uploader) and on our content whitelist do not fall under the 10:1 requirement. Action may be taken with Repeat offenders.\n",
      "\n",
      "4. **Generic/Off-Topic/Spam** - Spam consists of generic posts (Non-original posts, achievements, trophies etc), Off-topic posts, and memes/tier lists (Monday only). Common and/or general questions will be redirected to the Weekly Questions thread. Non-OC content (someone else‚Äôs artwork, cosplays etc) must follow a ratio of 5:1 comments to posts. Regardless of whether it‚Äôs uploaded on reddit or links outside of reddit.\n",
      "\n",
      "5. **No Politics** - Don't bring political commentary to /r/FinalFantasy, as it often leads to divisive arguments and frustration. We'll remove such comments and posts.\n",
      "\n",
      "6. **Use the questions megathread** - If you have a short or general question, please use the questions thread stickied to the top of the subreddit in order to prevent clutter on the sub. Some common questions such as \"which game should I play?\" or \"where should I start with the series?\" may also be redirected to the questions thread.\n",
      "\n",
      "7. **No Memes outside of Mondays** - No memes/image macros outside of \"Meme Monday\". For this purpose \"Meme Monday\" runs from 12:00 am EST to 11:59 pm EST. Therefore, any meme/macro/\"caption\" image that is posted outside of this time will be deleted. If it looks like a meme, it will be removed. This also includes tier lists.\n",
      "\n",
      "8. **Post Tagging** - Any original works (artwork, cosplay, music etc) is required to have [OC] at the beginning of the thread title OR be obvious that you are the creator. Non-OC works (artwork, cosplay, music etc) must credit the original artist in brackets at the end of the title i.e. ‚Äú[Artist Credit]‚Äù.\n",
      "\n",
      "9. **No Illegal and explicit content** - Any post or content discussing ROMs, pirated content, copyright infringement, sales or pornography will be removed.\n",
      "\n",
      "[Click here to read our rules in more detail!](https://www.reddit.com/r/FinalFantasy/wiki/rules)\n"
     ]
    }
   ],
   "source": [
    "print(subreddit.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "    **[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
    "    --------\n",
    "    +[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
    "    --------\n",
    "    +[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
    "    --------\n",
    "    +[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
    "    --------\n",
    "    +[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task II: Parse comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1. Top Posts of All Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Find titles of top 10 posts of **all time** from your favorite subreddit. Refer to [Obtain Submission Instances from a Subreddit Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)) if necessary. Verify if the titles match what you read on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# try run this line, what do you see? press q once you are done\n",
    "?subreddit.top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL FANTASY XVI ‚Äì Awakening Trailer | PS5\n",
      "FINAL FANTASY VII REMAKE Trailer for State of Play\n",
      "I sculpted a Chocobo!\n",
      "Please, save Net Neutrality. This may be our last chance.\n",
      "My girlfriend painted this for me.\n",
      "FF7 Remake is Real\n",
      "Was diagnosed with PTSD, therapist said I needed to do something constructive, here it begins.\n",
      "I made a promise to myself that I couldn‚Äôt play it until I hit 90 consecutive days of sobriety. Today is Day 90 and I‚Äôm proud that I did it. There‚Äôs not many people I can tell this to in my personal life so thanks for letting me share this accomplishment.\n",
      "You know what meme I‚Äôm talking about\n",
      "Never let the toxicity get to you. ‚ù§Ô∏è\n"
     ]
    }
   ],
   "source": [
    "for submission in subreddit.top(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details> <summary>Expected output:</summary>\n",
    "\n",
    "    [Project] From books to presentations in 10s with AR + ML\n",
    "    [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
    "    [R] First Order Motion Model applied to animate paintings\n",
    "    [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
    "    [D] This AI reveals how much time politicians stare at their phone at work\n",
    "    [D] Types of Machine Learning Papers\n",
    "    [D] The machine learning community has a toxicity problem\n",
    "    [Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
    "    [P] Using oil portraits and First Order Model to bring the paintings back to life\n",
    "    [D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG)    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2. Top 10 Posts of This Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What are the titles of the top 10 posts of **this week** from your favorite subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who‚Äôs excited for Final Fantasy XVI?!ü•≥üòÑ\n",
      "The infamous scene [art by nexeee]\n",
      "X-2 Yuna by hungry_clicker\n",
      "Happy Mother‚Äôs Day to the best mom a guy could ask for\n",
      "Spy x Fantasy [art by katsuartsu]\n",
      "Lighting by ffffcoffee\n",
      "The official non-canon couple..xD\n",
      "Today I finished Final Fantasy IX's achievements, completing the PS1 Final Fantasy classics\n",
      "My FFX Yuna Cosplay! [self] @/flowergirlbrooke\n",
      "Final Fantasy 17 should be set in Ivalice! We need more Yasumi, Yoshida and Sakimoto Magic ‚ù§Ô∏è\n"
     ]
    }
   ],
   "source": [
    "for submission in subreddit.top(limit=10, time_filter = 'week'):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details><summary>Expected output:</summary>\n",
    "\n",
    "    [N] Ian Goodfellow, Apple‚Äôs director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said ‚ÄúI believe strongly that more flexibility would have been the best policy for my team.‚Äù He was likely the company‚Äôs most cited ML expert.\n",
    "    [R][P] Thin-Plate Spline Motion Model for Image Animation + Gradio Web Demo\n",
    "    [P] I‚Äôve been trying to understand the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple‚Äôs version of MobileNet, and more directly on your phone's camera roll.\n",
    "    [R] Meta is releasing a 175B parameter language model\n",
    "    [N] Hugging Face raised $100M at $2B to double down on community, open-source & ethics\n",
    "    [P] T-SNE to view and order your Spotify tracks\n",
    "    [D] : HELP Finding a Book - A book written for Google Engineers about foundational Math to support ML\n",
    "    [R] Scaled up CLIP-like model (~2B) shows 86% Zero-shot on Imagenet\n",
    "    [D] Do you use NLTK or Spacy for text preprocessing?\n",
    "    [D] Democratizing Diffusion Models - LDMs: High-Resolution Image Synthesis with Latent Diffusion Models, a 5-minute paper summary by Casual GAN Papers\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3. Comment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add comments to the code block below to describe what each line of the code does (Refer to [Obtain Comment Instances Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html) when necessary). The code is adapted from [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
    "\n",
    "The purpose is \n",
    "1. to understand what the code is doing \n",
    "2. start to comment your code whenever it is not self-explantory if you have not (others will thank you, YOU will thank you later üòä) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 499 ms, sys: 24.1 ms, total: 523 ms\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# initialize an empty list to append comments to\n",
    "top_comments = []\n",
    "\n",
    "# Loops through the top 10 submissions in our choosen subredddit\n",
    "for submission in subreddit.top(limit=10):\n",
    "    # loops through all top level comments of the comments of the top 10 submissions. Top level comments are different in that the reply directly to the post rather than other comments\n",
    "    for top_level_comment in submission.comments:\n",
    "        # checks if a top level comment is also a MoreComments, making it truly NOT a top level comment, if this is the case, step to the next top_level_comment in the loop\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # append top level comments that are truly top level comments to the top comments submission\n",
    "        top_comments.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 4. Inspect Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How many comments did you extract from the last step? Examine a few comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE  # the answer may vary 693 for r/machinelearning\n",
    "len(top_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The first ff i played was 12 but at the time i couldnt understand the combat and also it was the first japanese game i played so i never passed the tutorial.',\n",
       " 'Bruh Final Fantasy XIII came out 12 years ago I don\\'t think people who started with that one can even be considered \"new\" fans anymore üòÇ.',\n",
       " 'If it wasn‚Äôt for FFXV, being a free Games With Gold a few years back, I‚Äôd probably never have finally started playing Final Fantasy. So yeah, sometimes, it‚Äôs that simple. And now I‚Äôve fallen in love with the whole rest of the series, and the JRPG Genre as a whole']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "[random.choice(top_comments) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> <summary>Some of the comments from `r/machinelearning` subreddit are:</summary>\n",
    "\n",
    "    ['Awesome visualisation',\n",
    "    'Similar to a stack or connected neurons.',\n",
    "    'Will this Turing pass the Turing Test?']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5. Extract Top Level Comment from Subreddit `TSLA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Write your code to extract top level comments from the top 10 topics of a time period, e.g., year, from subreddit `TSLA` and store them in a list `top_comments_tsla`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "subreddit = reddit.subreddit('TSLA')\n",
    "top_comments_tsla = []\n",
    "\n",
    "# Loops through the top 10 submissions in our choosen subredddit\n",
    "for submission in subreddit.top(limit=10):\n",
    "    # loops through all top level comments of the comments of the top 10 submissions. Top level comments are different in that the reply directly to the post rather than other comments\n",
    "    for top_level_comment in submission.comments:\n",
    "        # checks if a top level comment is also a MoreComments, making it truly NOT a top level comment, if this is the case, step to the next top_level_comment in the loop\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # append top level comments that are truly top level comments to the top comments submission\n",
    "        top_comments_tsla.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_comments_tsla) # Expected: 174 for r/machinelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here is a very interesting theory/conspiracy https://twitter.com/robgrav3s/status/1461111661310398469?s=10',\n",
       " 'Elon....come on.....we got ya...right?',\n",
       " 'Buy the dips, because Musk needs your money to pay his taxes.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[random.choice(top_comments_tsla) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Some of the comments from `r/TSLA` subreddit:</summary>\n",
    "\n",
    "    ['I bought puts',\n",
    "    '100%',\n",
    "    'Yes. And I‚Äôm bag holding 1200 calls for Friday and am close to throwing myself out the window']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task III: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us analyze the sentiment of comments scraped from `r/TSLA` using a pre-trained HuggingFace model to make the inference. Take a [Quick tour](https://huggingface.co/docs/transformers/quicktour). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Import `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2. Create a Pipeline to Perform Task \"sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf3e8b5bb6746ab946775762d7aa947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c997a5c57e1e400e93852162c3e7dea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c80b08ada4e406d8c5883f16b294c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a97d20302e04413b9e0e612167b0e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_model = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Get one comment from list `top_comments_tsla` from Task II - 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "comment = random.choice(top_comments_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla share is at 40% discount right now. Buy it or leave it.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example comment is: `'Bury Burry!!!!!'`. Print out what you get. For reproducibility, use the same comment in the next step; consider setting a seed.\n",
    "\n",
    "Comment for Tesla was: 'Tesla share is at 40% discount right now. Buy it or leave it.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Make Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9909082651138306}]\n"
     ]
    }
   ],
   "source": [
    "sentiment = sentiment_model(comment)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the type of the output `sentiment`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "[{'label': 'NEGATIVE', 'score': 0.9909082651138306}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment: Tesla share is at 40% discount right now. Buy it or leave it.\n",
      "Predicted Label is NEGATIVE and the score is 0.991\n"
     ]
    }
   ],
   "source": [
    "print(f'The comment: {comment}')\n",
    "print(f'Predicted Label is {sentiment[0][\"label\"]} and the score is {sentiment[0][\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example comment, the output is:\n",
    "\n",
    "    The comment: Bury Burry!!!!!\n",
    "    Predicted Label is NEGATIVE and the score is 0.989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task IV: Put All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull all the piece together, create a simple script that does \n",
    "\n",
    "- get the subreddit\n",
    "- get comments from the top posts for given subreddit\n",
    "- run sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you complete the code, running the following block writes the code into a new Python script and saves it as `top_tlsa_comment_sentiment.py` under the same directory with the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_tlsa_comment_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_tlsa_comment_sentiment.py\n",
    "\n",
    "import secrets\n",
    "import random\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "from praw import Reddit\n",
    "from praw.models.reddit.subreddit import Subreddit\n",
    "from praw.models import MoreComments\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def get_subreddit(display_name:str) -> Subreddit:\n",
    "    \"\"\"Get subreddit object from display name\n",
    "\n",
    "    Args:\n",
    "        display_name (str): [description]\n",
    "\n",
    "    Returns:\n",
    "        Subreddit: [description]\n",
    "    \"\"\"\n",
    "    reddit = Reddit(\n",
    "        client_id=secrets.REDDIT_API_CLIENT_ID,        \n",
    "        client_secret=secrets.REDDIT_API_CLIENT_SECRET,\n",
    "        user_agent=secrets.REDDIT_API_USER_AGENT\n",
    "        )\n",
    "    \n",
    "    subreddit = reddit.subreddit(display_name)\n",
    "    return subreddit\n",
    "\n",
    "def get_comments(subreddit:Subreddit, limit:int=3) -> List[str]:\n",
    "    \"\"\" Get comments from subreddit\n",
    "\n",
    "    Args:\n",
    "        subreddit (Subreddit): [description]\n",
    "        limit (int, optional): [description]. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of comments\n",
    "    \"\"\"\n",
    "    top_comments = []\n",
    "    for submission in subreddit.top(limit=limit):\n",
    "        for top_level_comment in submission.comments:\n",
    "            if isinstance(top_level_comment, MoreComments):\n",
    "                continue\n",
    "            top_comments.append(top_level_comment.body)\n",
    "    return top_comments\n",
    "\n",
    "def run_sentiment_analysis(comment:str) -> Dict:\n",
    "    \"\"\"Run sentiment analysis on comment using default distilbert model\n",
    "    \n",
    "    Args:\n",
    "        comment (str): [description]\n",
    "        \n",
    "    Returns:\n",
    "        str: Sentiment analysis result\n",
    "    \"\"\"\n",
    "    sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "    sentiment = sentiment_model(comment)\n",
    "    return sentiment[0]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    submission = get_subreddit('TSLA')\n",
    "    comments = get_comments(submission)\n",
    "    comment = comments[0]\n",
    "    sentiment = run_sentiment_analysis(comment)\n",
    "    \n",
    "    print(f'The comment: {comment}')\n",
    "    print(f'Predicted Label is {sentiment[\"label\"]} and the score is {sentiment[\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "The comment: ho lee fuk \n",
      "\n",
      "you got anymore insider information? üëÄüëÄ\n",
      "Predicted Label is NEGATIVE and the score is 0.994\n"
     ]
    }
   ],
   "source": [
    "!python top_tlsa_comment_sentiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Expected output:</summary>\n",
    "\n",
    "    No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "    The comment: When is DOGE flying\n",
    "    Predicted Label is POSITIVE and the score is 0.689\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70e5a9886b02a227d3c83e17263e3a28d12f842d6950be488144931078452c0e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
